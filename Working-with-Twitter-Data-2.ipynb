{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [Melanie Walsh](https://melaniewalsh.org/) for the 2022 Text Analysis Pedagogy Institute, with support from the [National Endowment for the Humanities](https://neh.gov), [JSTOR Labs](https://labs.jstor.org/), and [University of Arizona Libraries](https://new.library.arizona.edu/).\n",
    "\n",
    "For questions/comments/improvements, email melwalsh@uw.edu\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# Working with Twitter DataÂ (Lesson 2) â€” 6/22/2022\n",
    "\n",
    "This is lesson **2** of 3 in the educational series on **Working with Twitter Data**. This notebook will demonstrate how researchers can download tweet collections that have been shared by other people and share their own tweets in ways that honor users' right to be forgotten while also adhering to Twitter's Terms of Service. \n",
    "\n",
    "**Audience:** Teachers / Learners / Researchers\n",
    "\n",
    "**Use case:** Tutorial / How-To\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "**Completion time:** 30 minutes to 1 hour\n",
    "\n",
    "**Knowledge Required/Recommended:** \n",
    "\n",
    "* Command line knowledge\n",
    "* Python basics (variables, functions, lists, dictionaries)\n",
    "* Pandas basics (Python library for data manipulation and analysis)\n",
    "\n",
    "\n",
    "**Learning Objectives:**\n",
    "After this lesson, learners will be able to:\n",
    "\n",
    "1. Download tweet collections from a list of tweet IDs\n",
    "2. Convert tweets to tweet IDs for sharing purposes\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c0555",
   "metadata": {},
   "source": [
    "# Required Python Libraries\n",
    "* [twarc2](https://twarc-project.readthedocs.io/en/latest/twarc2_en_us/) for collecting Twitter data.\n",
    "* [plotly](https://plotly.com/python/) for making interactive plots \n",
    "* [pandas](https://pandas.pydata.org/) for manipulating and cleaning data\n",
    "\n",
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a220f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Libraries ###\n",
    "!pip install twarc --upgrade\n",
    "!pip install twarc-csv --upgrade\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5480e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "# Set max column width\n",
    "pd.options.display.max_colwidth = 400\n",
    "# Set max number of columns\n",
    "pd.options.display.max_columns = 95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbc763-1ccc-498e-9149-e083e09fae8b",
   "metadata": {},
   "source": [
    "# Twitter API Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02338a15-b842-4932-8d5f-3bc3f47d7be5",
   "metadata": {},
   "source": [
    "*This lesson presumes that you've already installed and configured twarc, which was covered in [a previous lesson](Twitter-API-Setup).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88aaf2a-218b-4a12-8e16-b78faa222bd8",
   "metadata": {},
   "source": [
    "## Configure Twarc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfcebde-bfd7-4164-bad8-af5794fe0b91",
   "metadata": {},
   "source": [
    "Once twarc is installed, you need to configure it with your API keys and/or bearer token so that you can actually access the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09141ce0-a3f1-4a56-a1de-84d0c761b2e7",
   "metadata": {},
   "source": [
    "To configure twarc, you would typically run `twarc2 configure` from the command line. This will prompt twarc to ask for your bearer token, which you can copy and paste into the blank after the colon, and then press enter. You can optionally enter your API keys, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f86f51-36dc-4833-9af2-32bb43763f03",
   "metadata": {},
   "source": [
    "<div class=\"admonition attention\" name=\"html-admonition\" style=\"background: orange; padding: 10px\">\n",
    "<p class=\"title\">Note</p>\n",
    "   To get your Bearer Token, go to your Twitter Developer portal: <a href= \"https://developer.twitter.com/en/portal/dashboard\">https://developer.twitter.com/en/portal/dashboard</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758aebed-a591-47eb-9a0f-bc7a66d67605",
   "metadata": {},
   "source": [
    "However, when working in a Jupyter notebook in the cloud, it is easiest to configure twarc and enter your Bearer Token in a single command. Please paste your Bearer Token between the quotations marks below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaebcf9-7bd7-45ff-adea-fcb5be519aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!printf '%s\\n' \"YOUR BEARER TOKEN HERE\" \"no\" | twarc2 configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec67b43-c517-4e48-a818-c2220f0e34de",
   "metadata": {},
   "source": [
    "Now you're ready to collect and analyze tweets!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af691423-df15-41c5-b530-806eefd1b397",
   "metadata": {},
   "source": [
    "## Tweet IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f0522-6c28-43b4-8ac4-b4ac26790aae",
   "metadata": {},
   "source": [
    "Twitter discourages developers and researchers from sharing full Twitter data openly on the web. They instead encourage developers and researchers to share *tweet IDs*:\n",
    "\n",
    "> [If you provide Twitter Content to third parties, including downloadable datasets or via an API, you may only distribute **Tweet IDs**, Direct Message IDs, and/or User IDs.](https://developer.twitter.com/en/developer-terms/policy#4-e)\n",
    "\n",
    "Tweet IDs are unique identifiers assigned to every tweet. They look like a random string of numbers: 1189206626135355397. Each tweet ID can be used to download the full data associated with that tweet (if the tweet still exists). This is a process called \"hydration.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d8c832-4ef6-48e0-925f-3ac6f0400f69",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.pixabay.com/photo/2013/07/12/19/24/sapling-154734_960_720.png\" width=100% >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e53537-b14b-473b-a63a-18ef7fea48df",
   "metadata": {},
   "source": [
    "**Hydration: a young tweet ID sprouts into a full tweet (to be read in David Attenborough's voice)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b017d-ce45-4763-81b0-936c9158ac3d",
   "metadata": {},
   "source": [
    "There are actually two reasons that you might want to dehydrate tweets and/or hydrate tweet IDs: first, to responsibly share Twitter data with others and/or access Twitter data shared by others; second, to get more information about the Twitter data that you yourself collected.\n",
    "\n",
    "If you collected tweets in real time, for example, you collected those tweets immediately after they were published, which means that they will not contain any retweet or favorite count information. Nobody's had time to retweet them yet! So if you'd like to retroactively get retweet and favorite count information about your tweets, then you would want to dehydrate and rehydrate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fed50e-7780-44aa-8f3c-13c8fe3d9be3",
   "metadata": {},
   "source": [
    "## Hydrate Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed3a84-c484-4ef2-ab26-788329670130",
   "metadata": {},
   "source": [
    "`twarc2 hydrate tweet_ids.txt > tweets.jsonl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc033f-b1fb-4aa4-9531-3a602a675da9",
   "metadata": {},
   "source": [
    "To transform a list of tweet IDs into full Twitter data, you can run the twarc command `twarc2 hydrate` with the name of your tweet IDs text file followed by the output operator `>` and the desired name of your JSONL file.\n",
    "\n",
    "> tweet ID â€”> tweet = hydration <br>\n",
    "> tweet ID <â€” tweet = dehydration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9634ce4-4da9-4b04-93df-bb458f9f266b",
   "metadata": {},
   "source": [
    "Kevin McElwee conducted a [fascinating analysis](https://www.kmcelwee.com/fortune-100-blm-report/site/index.html) of Fortune 100 companies' response to the #BlackLivesMatter protests following George Floyd's death in May 2020. He collected tweets from 91 of these companies' Twitter accounts between May 25 and July 25, 2020, and he then shared these tweets as [tweet IDs](https://github.com/kmcelwee/fortune-100-blm-dataset/blob/main/data/ids/fortune-100-tweet-ids.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abd760-af9f-4cd6-8015-fd41ca94254d",
   "metadata": {},
   "source": [
    "Let's re-hydrate the Twitter data that McElwee collected about these Fortune 100 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ac4979-bc89-4f3d-b907-486611e09a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 hydrate fortune-100-tweet-ids.txt > fortune-100-tweets.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "930db0ec-5448-47b3-bd65-6c40bd93e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Processed 17.6M/17.6M of input file [00:02<00:00, 6.99MB/s]\n",
      "\n",
      "â„¹ï¸\n",
      "Parsed 6071 tweets objects from 62 lines in the input file.\n",
      "Wrote 6071 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!twarc2 csv fortune-100-tweets.jsonl fortune-100-tweets.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a42226-14df-4894-a692-a0398c6a26ce",
   "metadata": {},
   "source": [
    "Read in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f145a0b-c624-4878-a131-8d72b67f825e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('fortune-100-tweets.csv', parse_dates = ['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c2126-3796-43cf-b34e-421f15074cab",
   "metadata": {},
   "source": [
    "Let's apply the helper functions and create new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b36e22a8-b5e4-439c-9019-c075f613b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the type of tweet\n",
    "def find_type(tweet):\n",
    "    \n",
    "    # Check to see if tweet contains retweet, quote tweet, or reply tweet info\n",
    "    contains_retweet = tweet['referenced_tweets.retweeted.id']\n",
    "    contains_quote = tweet['referenced_tweets.quoted.id']\n",
    "    contains_reply = tweet['referenced_tweets.replied_to.id']\n",
    "    \n",
    "    # Does tweet contain retweet info? (Is this category not NA or empty?)\n",
    "    if pd.notna(contains_retweet):\n",
    "        return \"retweet\"\n",
    "    # Does tweet contain quote and reply info?\n",
    "    elif pd.notna(contains_quote) and pd.notna(contains_reply):\n",
    "        return \"quote/reply\"\n",
    "    # Does tweet contain quote info? \n",
    "    elif pd.notna(contains_quote):\n",
    "        return \"quote\"\n",
    "    # Does tweet contain reply info? \n",
    "    elif pd.notna(contains_reply):\n",
    "        return \"reply\"\n",
    "    # If it doesn't contain any of this info, it must be an original tweet\n",
    "    else:\n",
    "        return \"original\"\n",
    "\n",
    "# Make Tweet URL\n",
    "def make_tweet_url(tweets):\n",
    "    # Get username\n",
    "    username = tweets[0]\n",
    "    # Get tweet ID\n",
    "    tweet_id = tweets[1]\n",
    "    # Make tweet URL\n",
    "    tweet_url = f\"https://twitter.com/{username}/status/{tweet_id}\"\n",
    "    return tweet_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fcfa8c3-f7bf-4117-b539-68f324a7f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweet type column\n",
    "tweets_df['type'] = tweets_df.apply(find_type, axis =1)\n",
    "# Create tweet URL column\n",
    "tweets_df['tweet_url'] = tweets_df[['author.username', 'id']].apply(make_tweet_url, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6501b-ec3a-4871-b731-d134f45ce32e",
   "metadata": {},
   "source": [
    "Let's select and rename only the columns we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bcc77-735e-49f8-9c75-e9505c73d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of interest\n",
    "clean_tweets_df = tweets_df[['created_at', 'author.username', 'author.name', 'author.description',\n",
    "                             'author.verified', 'type', 'text', 'public_metrics.retweet_count', \n",
    "                             'public_metrics.like_count', 'public_metrics.reply_count', 'public_metrics.quote_count',\n",
    "                             'tweet_url', 'lang', 'source', 'geo.full_name']]\n",
    "\n",
    "# Rename columns for convenience\n",
    "clean_tweets_df = clean_tweets_df.rename(columns={'created_at': 'date', 'public_metrics.retweet_count': 'retweets', \n",
    "                          'author.username': 'username', 'author.name': 'name', 'author.verified': 'verified', \n",
    "                          'public_metrics.like_count': 'likes', 'public_metrics.quote_count': 'quotes', \n",
    "                          'public_metrics.reply_count': 'replies', 'author.description': 'user_bio'})\n",
    "\n",
    "clean_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ada66d-0e66-4786-a66c-bc5d8a8ecd79",
   "metadata": {},
   "source": [
    "### Sort By Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf9893-e52a-46c4-a74b-832c30b2c672",
   "metadata": {},
   "source": [
    "What are the top retweeted tweets? We can use [pandas `sort_values()` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) to sort any column in ascending or descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d53b5-bbda-47a9-becb-63f8a28a7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df.sort_values(by=\"retweets\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f78ee2-fa92-440e-931a-71d1b21e4c5b",
   "metadata": {},
   "source": [
    "### Count Tweets Per Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb00fa3-ae86-47b2-907e-3593bea01759",
   "metadata": {},
   "source": [
    "How many tweets from each company are here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf42225-2335-4afd-bfae-63cb511abe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a921d5-7675-4191-8b23-9915a1c60d6d",
   "metadata": {},
   "source": [
    "## Filter tweets by text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33881f-4de3-42bb-994b-19aac7f44d22",
   "metadata": {},
   "source": [
    "How many tweets contain the word \"Black\" as in \"Black Americans\" or \"Black Lives Matter\"? We can use [pandas `.str.contains()` method](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html) to search for specific text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8d882-5a3a-4ea3-85ab-2674f6756bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filter = clean_tweets_df['text'].str.contains(\"Black\")\n",
    "clean_tweets_df[text_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3066f3-5b72-4330-927c-89e0e372e5b2",
   "metadata": {},
   "source": [
    "Kevin McElwee's analysis is also an excellent example of what's possible when you combine computational work with qualitative coding and hand tagging: https://www.kmcelwee.com/fortune-100-blm-report/site/corporate-summaries.htmlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae451ad-ac2f-4a47-b287-41f7d1463d36",
   "metadata": {},
   "source": [
    "## Dehydrate Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19056a2a-6b63-4fee-a1ae-b9d865d95c12",
   "metadata": {},
   "source": [
    "`twarc2 dehydrate tweets.jsonl > tweet_ids.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08580867-5d01-49a8-a8c3-44e13f256710",
   "metadata": {},
   "source": [
    "To transform your Twitter own data into a list of tweet IDs (so that you can share your data openly on the web), you can run the twarc command `twarc2 dehydrate` with the name of your JSONL file followed by the output operator `>` and the desired name of your tweet ID text file.\n",
    "\n",
    "> tweet ID â€”> tweet = hydration <br>\n",
    "> tweet ID <â€” tweet = dehydration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac32ed1-0120-4f7b-a149-6068f9fe5cb7",
   "metadata": {},
   "source": [
    "<div class=\"admonition attention\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"title\">Attention ðŸš¨</p>\n",
    "    Remember that the <code>--archive</code> flag and full-archive search functionality is only available to those who have an <a href= \"https://developer.twitter.com/en/products/twitter-api/academic-research\">Academic Research account</a>. \n",
    "    Students with Essential API access should remove the <code>--archive</code> flag from the code below.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a30db749-ee34-4ef9-a209-bb58dc7cc0be",
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "!twarc2 search --archive \"plums in the icebox is:verified\" --limit 500 > tweets.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c1ff1-e484-483d-8a8c-5b67093f742e",
   "metadata": {},
   "source": [
    "Let's dehydrate the Twitter data that we collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cb09fb6-a503-4ef6-972a-41a4d3b360cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸  Parsed 578 tweets IDs from 6 lines in tweets.jsonl file.\n"
     ]
    }
   ],
   "source": [
    "!twarc2 dehydrate tweets.jsonl > tweets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17654b-5457-41a7-8b80-ba445096a730",
   "metadata": {},
   "source": [
    "If we `open()` and `.read()` the tweet IDs file that we just created, it looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad5a90-517c-4cca-bbbd-0050a46d624c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_ids = open(\"tweets.txt\", encoding=\"utf-8\").read()\n",
    "print(tweet_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e75127-bb20-41dc-a245-33502dd0d81d",
   "metadata": {},
   "source": [
    "## Where to Find Tweet IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782fd122-003c-4f7d-9c7d-9a8427be63db",
   "metadata": {},
   "source": [
    "You can find repositories of tweet IDs that have been shared by other researchers in the following places:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf61a7a-331f-4d93-8542-ff133ad88331",
   "metadata": {},
   "source": [
    "- DocNow Catalog: https://catalog.docnow.io/\n",
    "\n",
    "- George Washington University Tweet IDs: https://dataverse.harvard.edu/dataverse/gwu-libraries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
