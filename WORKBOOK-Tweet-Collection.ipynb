{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [Melanie Walsh](https://melaniewalsh.org/) for the 2022 Text Analysis Pedagogy Institute, with support from the [National Endowment for the Humanities](https://neh.gov), [JSTOR Labs](https://labs.jstor.org/), and [University of Arizona Libraries](https://new.library.arizona.edu/).\n",
    "\n",
    "For questions/comments/improvements, email melwalsh@uw.edu\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# Tweet Collection (Workbook) — June 2022\n",
    "\n",
    "Here's a streamlined workbook for collecting tweet counts and tweets.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b85a87-a8e1-4496-95de-595f8c9b3f0c",
   "metadata": {},
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a220f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Libraries ###\n",
    "!pip install twarc --upgrade\n",
    "!pip install twarc-csv --upgrade\n",
    "!pip install plotly\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5480e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Set max column width\n",
    "pd.options.display.max_colwidth = 400\n",
    "# Set max number of columns\n",
    "pd.options.display.max_columns = 95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbc763-1ccc-498e-9149-e083e09fae8b",
   "metadata": {},
   "source": [
    "# Twitter API Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88aaf2a-218b-4a12-8e16-b78faa222bd8",
   "metadata": {},
   "source": [
    "## Configure Twarc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfcebde-bfd7-4164-bad8-af5794fe0b91",
   "metadata": {},
   "source": [
    "Once twarc is installed, you need to configure it with your API keys and/or bearer token so that you can actually access the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09141ce0-a3f1-4a56-a1de-84d0c761b2e7",
   "metadata": {},
   "source": [
    "To configure twarc, you would typically run `twarc2 configure` from the command line. This will prompt twarc to ask for your bearer token, which you can copy and paste into the blank after the colon, and then press enter. You can optionally enter your API keys, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaebcf9-7bd7-45ff-adea-fcb5be519aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!printf '%s\\n' \"YOUR BEARER TOKEN HERE\" \"no\" | twarc2 configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e3c57-6716-4feb-b4db-7913a9651e06",
   "metadata": {},
   "source": [
    "If you've entered your information correctly, you should get a congratulatory message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfea96-97cd-4ac3-b238-7042067c040b",
   "metadata": {},
   "source": [
    "# Twitter Data Collection & Visualization\n",
    "## Get Tweet Counts and Save as Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f11f1cb-55af-43fe-b2cc-91aa2aca7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 counts \"your query\" --csv --archive --granularity day > query-tweet-counts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42f154-7069-4236-a52c-e89fd87f045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the title of the plot here\n",
    "my_title = \"YOUR TITLE HERE\"\n",
    "# Change the file name here\n",
    "filename = \"YOUR FILENAME HERE\"\n",
    "\n",
    "# Read in CSV as DataFrame\n",
    "tweet_counts_df = pd.read_csv(filename, parse_dates=['start', 'end'])\n",
    "\n",
    "# Set start time as DataFrame index\n",
    "tweet_counts_df.set_index('start', inplace=True)\n",
    "\n",
    "# Regroup, or resample, tweets by month, day, or year\n",
    "grouped_count = tweet_counts_df.resample('M')['day_count'].sum().reset_index() # Month\n",
    "#grouped_count = tweet_counts_df.resample('D')['day_count'].sum().reset_index() # Day\n",
    "#grouped_count = tweet_counts_df.resample('Y')['day_count'].sum().reset_index() # Year\n",
    "\n",
    "# Make a line plot from the DataFrame and specify x and y axes, axes titles, and plot title\n",
    "px.line(grouped_count, x = 'start', y = 'day_count',\n",
    "    labels = {'start': 'Time', 'day_count': '# of Tweets'},\n",
    "    title = my_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893525e5-75e8-444f-8a15-a31a80b08174",
   "metadata": {},
   "source": [
    "## Get Tweets and Save as Spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059e86b-7daa-405a-a7ae-655016063457",
   "metadata": {},
   "source": [
    "To actually collect tweets and their associated metadata, we can use the command `twarc2 search` and insert a query.\n",
    "\n",
    "Here we're going to search for any tweets that mention certain words and were tweeted by verified accounts. By default, `twarc2 search` will use the essential track of the Twitter API, which only collects tweets from the past week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8938c24-5f5e-40af-91e2-f6c3adf5dab9",
   "metadata": {},
   "source": [
    "<div class=\"admonition attention\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"title\">Attention 🚨</p>\n",
    "    Remember that the <code>--archive</code> flag and full-archive search functionality is only available to those who have an <a href= \"https://developer.twitter.com/en/products/twitter-api/academic-research\">Academic Research account</a>. \n",
    "    Students with Essential API access should remove the <code>--archive</code> flag from the code below.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a4b26-726f-49e1-8e71-d2760a8b2c91",
   "metadata": {},
   "source": [
    "You might want to limit your search to 5000 tweets or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1036d813-4b14-4489-ba5b-2eaf77da42c9",
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "!twarc2 search --archive --limit 5000 \"YOUR QUERY\" > my_tweets.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f488964b-58fd-4440-a7ec-565377f0f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 3.36M/3.36M of input file [00:00<00:00, 7.44MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 1550 tweets objects from 17 lines in the input file.\n",
      "Wrote 1550 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!twarc2 csv my_tweets.jsonl my_tweets.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee670d6c-fad6-4c1a-bc9b-91a22b8b40a5",
   "metadata": {},
   "source": [
    "Now we're ready to explore the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056954b-af42-41ff-966b-42753af04507",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_tweets_df = pd.read_csv('my_tweets.csv', parse_dates = ['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5534fcc-cab2-4bc2-b23a-84b835570ecc",
   "metadata": {},
   "source": [
    "Let's apply the helper functions and create new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b8b4139-67af-472b-86a4-07bb95f0a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the type of tweet\n",
    "def find_type(tweet):\n",
    "    \n",
    "    # Check to see if tweet contains retweet, quote tweet, or reply tweet info\n",
    "    contains_retweet = tweet['referenced_tweets.retweeted.id']\n",
    "    contains_quote = tweet['referenced_tweets.quoted.id']\n",
    "    contains_reply = tweet['referenced_tweets.replied_to.id']\n",
    "    \n",
    "    # Does tweet contain retweet info? (Is this category not NA or empty?)\n",
    "    if pd.notna(contains_retweet):\n",
    "        return \"retweet\"\n",
    "    # Does tweet contain quote and reply info?\n",
    "    elif pd.notna(contains_quote) and pd.notna(contains_reply):\n",
    "        return \"quote/reply\"\n",
    "    # Does tweet contain quote info? \n",
    "    elif pd.notna(contains_quote):\n",
    "        return \"quote\"\n",
    "    # Does tweet contain reply info? \n",
    "    elif pd.notna(contains_reply):\n",
    "        return \"reply\"\n",
    "    # If it doesn't contain any of this info, it must be an original tweet\n",
    "    else:\n",
    "        return \"original\"\n",
    "\n",
    "# Make Tweet URL\n",
    "def make_tweet_url(tweets):\n",
    "    # Get username\n",
    "    username = tweets[0]\n",
    "    # Get tweet ID\n",
    "    tweet_id = tweets[1]\n",
    "    # Make tweet URL\n",
    "    tweet_url = f\"https://twitter.com/{username}/status/{tweet_id}\"\n",
    "    return tweet_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b85dec6-694e-4084-8571-0347a73f8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweet type column\n",
    "my_tweets_df['type'] =my_tweets_df.apply(find_type, axis =1)\n",
    "# Create tweet URL column\n",
    "my_tweets_df['tweet_url'] = my_tweets_df[['author.username', 'id']].apply(make_tweet_url, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9fd65-0031-4bdf-ba21-c8c28cca7bd6",
   "metadata": {},
   "source": [
    "Let's select and rename only the columns we're interested in.\n",
    "\n",
    "Pick another new column that you find intriguing and add it below!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f9b48-9710-43f3-9798-bc97312c068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of interest\n",
    "my_clean_tweets_df = my_tweets_df[['created_at', 'author.username', 'author.name', 'author.description',\n",
    "                             'author.verified', 'type', 'text', 'public_metrics.retweet_count', \n",
    "                             'public_metrics.like_count', 'public_metrics.reply_count', 'public_metrics.quote_count',\n",
    "                             'tweet_url', 'lang', 'source', 'geo.full_name']]\n",
    "\n",
    "# Rename columns for convenience\n",
    "my_clean_tweets_df = my_clean_tweets_df.rename(columns={'created_at': 'date', 'public_metrics.retweet_count': 'retweets', \n",
    "                          'author.username': 'username', 'author.name': 'name', 'author.verified': 'verified', \n",
    "                          'public_metrics.like_count': 'likes', 'public_metrics.quote_count': 'quotes', \n",
    "                          'public_metrics.reply_count': 'replies', 'author.description': 'user_bio'})\n",
    "\n",
    "my_clean_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4b945-73ca-4792-b317-dfbb1163d0d9",
   "metadata": {},
   "source": [
    "Let's get an overview of some of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc53a0-31f4-47e3-b039-72715d0772f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clean_tweets_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133b156-e649-4e5a-8b53-d92f8e9512f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stopwords list\n",
    "stopwords = STOPWORDS.update([\"plums\", \"icebox\"])\n",
    "\n",
    "# Set up wordcloud\n",
    "wc = WordCloud(background_color=\"white\", max_words=50,\n",
    "               stopwords=stopwords, contour_width=5, contour_color='steelblue')\n",
    "\n",
    "# Strip line breaks\n",
    "tweet_texts = my_clean_tweets_df['text'].str.replace(r\"\\\\n\", \" \", regex=True)\n",
    "# Join all tweet texts together\n",
    "tweet_texts = ' '.join(tweet_texts)\n",
    "# Generate word cloud\n",
    "wc.generate(tweet_texts)\n",
    "\n",
    "# Create and save word cloud\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"my_tweet_word-cloud.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
